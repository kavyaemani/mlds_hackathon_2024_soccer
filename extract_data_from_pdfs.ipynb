{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a64eb1-11ab-4063-a7df-83c3226755e9",
   "metadata": {},
   "source": [
    "# Retrieve All PDF File Paths from a Directory and Subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aab70f8f-12e3-4cf9-b499-04d5f871a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 184 PDF files were found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Function to retrieve paths of all PDF files\n",
    "def get_all_pdf_files(root_folder):\n",
    "    pdf_files = []\n",
    "    # Traverse the directory and its subdirectories to find PDF files\n",
    "    for folder_name, subfolders, filenames in os.walk(root_folder):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.pdf'):\n",
    "                pdf_files.append(os.path.join(folder_name, filename))\n",
    "    return pdf_files\n",
    "\n",
    "# Example usage\n",
    "os.getcwd()\n",
    "root_folder = os.path.join(os.getcwd(), \"match-reports\")\n",
    "pdf_files = get_all_pdf_files(root_folder)\n",
    "print(f\"A total of {len(pdf_files)} PDF files were found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e01cd56-e119-4019-883b-22a3653cb54f",
   "metadata": {},
   "source": [
    "# Match Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be713cc1-63ab-4c52-9464-b73dade81a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                file             team1  \\\n",
      "0  c:\\Users\\John\\Desktop\\Hackathon 2024\\hackathon...   Butler Bulldogs   \n",
      "1  c:\\Users\\John\\Desktop\\Hackathon 2024\\hackathon...  Indiana Hoosiers   \n",
      "2  c:\\Users\\John\\Desktop\\Hackathon 2024\\hackathon...  Indiana Hoosiers   \n",
      "3  c:\\Users\\John\\Desktop\\Hackathon 2024\\hackathon...  Indiana Hoosiers   \n",
      "4  c:\\Users\\John\\Desktop\\Hackathon 2024\\hackathon...  Indiana Hoosiers   \n",
      "\n",
      "                             team2  score1  score2        date  \n",
      "0                 Indiana Hoosiers       1       1  05.09.2024  \n",
      "1                    Dayton Flyers       0       2  10.09.2024  \n",
      "2           Evansville Purple Aces       1       1  18.09.2024  \n",
      "3                Kentucky Wildcats       3       2  09.10.2024  \n",
      "4  Maryland College Park Terrapins       0       1  21.09.2024  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Get a list of all PDF files from the specified folder and its subfolders\n",
    "def get_all_pdf_files(root_folder):\n",
    "    pdf_files = []\n",
    "    for folder_name, subfolders, filenames in os.walk(root_folder):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.pdf'):\n",
    "                pdf_files.append(os.path.join(folder_name, filename))\n",
    "    return pdf_files\n",
    "\n",
    "# Extract team, score, and date information from a PDF file\n",
    "def extract_match_data(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        # Extract data from the second page (index starts at 0)\n",
    "        page = pdf.pages[1]  # Select the second page\n",
    "        text = page.extract_text()\n",
    "        \n",
    "        # Split the text into lines\n",
    "        lines = text.split('\\n')\n",
    "\n",
    "        # Extract team names and scores (find the line containing '–')\n",
    "        match_line = [line for line in lines if '–' in line][0]\n",
    "        teams_and_scores = match_line.strip()\n",
    "\n",
    "        # Split team names and scores using regex\n",
    "        match_parts = re.split(r' (\\d+) – (\\d+) ', teams_and_scores)\n",
    "        team1 = match_parts[0].strip().replace(\"MATCH SHEET\", \"\").strip()  # Remove \"MATCH SHEET\"\n",
    "        score1 = int(match_parts[1])\n",
    "        score2 = int(match_parts[2])\n",
    "        team2 = match_parts[3].strip().replace(\"MATCH SHEET\", \"\").strip()  # Remove \"MATCH SHEET\"\n",
    "\n",
    "        # Extract the date (find the line enclosed in parentheses)\n",
    "        date_line = [line for line in lines if '(' in line][0]\n",
    "        match_date = date_line.split('(')[-1].replace(')', '').strip()\n",
    "\n",
    "        return {\n",
    "            \"file\": pdf_path,  # Path to the PDF file\n",
    "            \"team1\": team1,    # Name of the first team\n",
    "            \"team2\": team2,    # Name of the second team\n",
    "            \"score1\": score1,  # Score of the first team\n",
    "            \"score2\": score2,  # Score of the second team\n",
    "            \"date\": match_date # Match date\n",
    "        }\n",
    "\n",
    "# Process all PDF files in the folder\n",
    "def process_all_pdfs(root_folder):\n",
    "    pdf_files = get_all_pdf_files(root_folder)\n",
    "    all_data = []\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        try:\n",
    "            data = extract_match_data(pdf_file)\n",
    "            all_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pdf_file}: {e}\")\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "# Example usage\n",
    "root_folder = os.path.join(os.getcwd(), \"match-reports\")\n",
    "all_pdf_data = process_all_pdfs(root_folder)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_pdf_data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"match_data_cleaned.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "# Display the top 5 rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b65af4e-b60c-409b-99a8-51cd7c72bb70",
   "metadata": {},
   "source": [
    "# Substitution Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17e4e50d-1b3e-4b8b-9bf1-2254535aeaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Lineups:\n",
      "  Position Number         Player    In   Out   In2  Out2   In3  \\\n",
      "0       GK      1      C. Norris  None  None  None  None  None   \n",
      "1       GK      1       J. Harms  None  None  None  None  None   \n",
      "2       RB     17    H. Kumwenda   44'  None  None  None  None   \n",
      "3       RB      2      Q. Elliot  None  None  None  None  None   \n",
      "4      RCB      3  V. Verkooijen  None  None  None  None  None   \n",
      "\n",
      "                                                file  \n",
      "0  c:\\Users\\John\\Desktop\\Hackathon 2024\\hackathon...  \n",
      "1  c:\\Users\\John\\Desktop\\Hackathon 2024\\hackathon...  \n",
      "2  c:\\Users\\John\\Desktop\\Hackathon 2024\\hackathon...  \n",
      "3  c:\\Users\\John\\Desktop\\Hackathon 2024\\hackathon...  \n",
      "4  c:\\Users\\John\\Desktop\\Hackathon 2024\\hackathon...  \n",
      "\n",
      "Substitutes:\n",
      "  Position Number      Player   In  Out   In2  Out2   In3  \\\n",
      "0     RAMF      7    N. Okoro  31'  46'   49'   59'   85'   \n",
      "1       CF     12    M. Nesci  30'  46'   82'  None  None   \n",
      "2     LAMF     27     L. Raso  39'  46'  None  None  None   \n",
      "3       LW     20  C. Murador  30'  65'  None  None  None   \n",
      "4     LDMF     28    D. Boone  39'  46'   69'  None  None   \n",
      "\n",
      "                                                file  \n",
      "0  c:\\Users\\John\\Desktop\\Hackathon 2024\\hackathon...  \n",
      "1  c:\\Users\\John\\Desktop\\Hackathon 2024\\hackathon...  \n",
      "2  c:\\Users\\John\\Desktop\\Hackathon 2024\\hackathon...  \n",
      "3  c:\\Users\\John\\Desktop\\Hackathon 2024\\hackathon...  \n",
      "4  c:\\Users\\John\\Desktop\\Hackathon 2024\\hackathon...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to get all PDF files from the specified folder and its subfolders\n",
    "def get_all_pdf_files(root_folder):\n",
    "    pdf_files = []\n",
    "    for folder_name, subfolders, filenames in os.walk(root_folder):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.pdf'):\n",
    "                pdf_files.append(os.path.join(folder_name, filename))\n",
    "    return pdf_files\n",
    "\n",
    "# Function to parse the starting lineup and substitutes from a PDF\n",
    "def parse_lineup_and_substitutes(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        page = pdf.pages[1]  # Select the 2nd page\n",
    "        text = page.extract_text()\n",
    "\n",
    "        # Extract \"Starting Lineup\" and \"Substitutes\" sections\n",
    "        starting_lineup_match = re.search(r\"Starting lineup\\n(.*?)\\nSubstitutes\", text, re.S)\n",
    "        substitutes_match = re.search(r\"Substitutes\\n(.*?)\\nCoaches\", text, re.S)\n",
    "\n",
    "        # Parse each section\n",
    "        starting_lineup_data = parse_players(starting_lineup_match.group(1)) if starting_lineup_match else []\n",
    "        substitutes_data = parse_players(substitutes_match.group(1)) if substitutes_match else []\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        starting_lineup_df = pd.DataFrame(starting_lineup_data)\n",
    "        substitutes_df = pd.DataFrame(substitutes_data)\n",
    "\n",
    "        return starting_lineup_df, substitutes_df\n",
    "\n",
    "# Function to parse player data with support for multiple in/out times\n",
    "def parse_players(section_text):\n",
    "    pattern = r'(\\w+)\\s+(\\d+)\\s+([A-Z]\\.\\s*[A-Za-z]+)(?:\\s*((?:\\d+(?:\\+\\d+)?\\')*(?:\\s+\\d+(?:\\+\\d+)?\\')*))'\n",
    "    matches = re.findall(pattern, section_text)\n",
    "    \n",
    "    data = []\n",
    "    for match in matches:\n",
    "        position, number, player, times = match\n",
    "        \n",
    "        time_pattern = r'(\\d+(?:\\+\\d+)?)\\''\n",
    "        times_list = re.findall(time_pattern, times)\n",
    "        \n",
    "        player_data = {\n",
    "            'Position': position,\n",
    "            'Number': number,\n",
    "            'Player': player,\n",
    "            'In': None,\n",
    "            'Out': None,\n",
    "            'In2': None,\n",
    "            'Out2': None,\n",
    "            'In3': None\n",
    "        }\n",
    "        \n",
    "        if times_list:\n",
    "            if len(times_list) >= 1:\n",
    "                player_data['In'] = times_list[0] + \"'\"\n",
    "            if len(times_list) >= 2:\n",
    "                player_data['Out'] = times_list[1] + \"'\"\n",
    "            if len(times_list) >= 3:\n",
    "                player_data['In2'] = times_list[2] + \"'\"\n",
    "            if len(times_list) >= 4:\n",
    "                player_data['Out2'] = times_list[3] + \"'\"\n",
    "            if len(times_list) >= 5:\n",
    "                player_data['In3'] = times_list[4] + \"'\"\n",
    "        \n",
    "        data.append(player_data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Function to process all PDFs in the folder\n",
    "def process_all_pdfs(root_folder):\n",
    "    pdf_files = get_all_pdf_files(root_folder)\n",
    "    all_starting_lineups = []\n",
    "    all_substitutes = []\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        try:\n",
    "            starting_lineup_df, substitutes_df = parse_lineup_and_substitutes(pdf_file)\n",
    "            # Add a column to indicate the file source\n",
    "            starting_lineup_df['file'] = pdf_file\n",
    "            substitutes_df['file'] = pdf_file\n",
    "            all_starting_lineups.append(starting_lineup_df)\n",
    "            all_substitutes.append(substitutes_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pdf_file}: {e}\")\n",
    "\n",
    "    # Combine all data into single DataFrames\n",
    "    combined_starting_lineups = pd.concat(all_starting_lineups, ignore_index=True)\n",
    "    combined_substitutes = pd.concat(all_substitutes, ignore_index=True)\n",
    "    \n",
    "    return combined_starting_lineups, combined_substitutes\n",
    "\n",
    "# Example usage\n",
    "root_folder = os.path.join(os.getcwd(), \"match-reports\")\n",
    "starting_lineups_df, substitutes_df = process_all_pdfs(root_folder)\n",
    "\n",
    "# Display results\n",
    "print(\"Starting Lineups:\")\n",
    "print(starting_lineups_df.head())\n",
    "print(\"\\nSubstitutes:\")\n",
    "print(substitutes_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a6f57-9a7e-47fe-ab6e-5ca9baa28eb9",
   "metadata": {},
   "source": [
    "### Extract Match information, Starting line up and substitutes data as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6822d6-a895-46f1-9038-c82d11e92264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files created: match_data.csv, starting_lineups.csv, substitutes.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Get a list of all PDF files from the specified folder and its subfolders\n",
    "def get_all_pdf_files(root_folder):\n",
    "    pdf_files = []\n",
    "    for folder_name, subfolders, filenames in os.walk(root_folder):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.pdf'):\n",
    "                pdf_files.append(os.path.join(folder_name, filename))\n",
    "    return pdf_files\n",
    "\n",
    "# Extract match information: team names, scores, and date\n",
    "def extract_match_data(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        page = pdf.pages[1]  # Second page\n",
    "        text = page.extract_text()\n",
    "        \n",
    "        # Extract teams and scores\n",
    "        match_line = [line for line in text.split('\\n') if '–' in line][0]\n",
    "        match_parts = re.split(r' (\\d+) – (\\d+) ', match_line)\n",
    "        team1 = match_parts[0].strip().replace(\"MATCH SHEET\", \"\").strip()  # Remove \"MATCH SHEET\"\n",
    "        score1 = int(match_parts[1])\n",
    "        score2 = int(match_parts[2])\n",
    "        team2 = match_parts[3].strip().replace(\"MATCH SHEET\", \"\").strip()  # Remove \"MATCH SHEET\"\n",
    "        \n",
    "        # Extract match date\n",
    "        date_line = [line for line in text.split('\\n') if '(' in line][0]\n",
    "        match_date = date_line.split('(')[-1].replace(')', '').strip()\n",
    "\n",
    "        return {\n",
    "            \"team1\": team1,\n",
    "            \"score1\": score1,\n",
    "            \"score2\": score2,\n",
    "            \"team2\": team2,\n",
    "            \"date\": match_date\n",
    "        }\n",
    "\n",
    "# Extract starting lineup and substitutes\n",
    "def parse_lineup_and_substitutes(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        page = pdf.pages[1]  # Second page\n",
    "        text = page.extract_text()\n",
    "\n",
    "        # Extract \"Starting Lineup\" and \"Substitutes\" sections\n",
    "        starting_lineup_match = re.search(r\"Starting lineup\\n(.*?)\\nSubstitutes\", text, re.S)\n",
    "        substitutes_match = re.search(r\"Substitutes\\n(.*?)\\nCoaches\", text, re.S)\n",
    "\n",
    "        # Parse each section\n",
    "        starting_lineup_data = parse_players(starting_lineup_match.group(1)) if starting_lineup_match else []\n",
    "        substitutes_data = parse_players(substitutes_match.group(1)) if substitutes_match else []\n",
    "\n",
    "        return pd.DataFrame(starting_lineup_data), pd.DataFrame(substitutes_data)\n",
    "\n",
    "# Parse player data with support for multiple in/out times\n",
    "def parse_players(section_text):\n",
    "    pattern = r'(\\w+)\\s+(\\d+)\\s+([A-Z]\\.\\s*[A-Za-z]+)(?:\\s*((?:\\d+(?:\\+\\d+)?\\')*(?:\\s+\\d+(?:\\+\\d+)?\\')*))'\n",
    "    matches = re.findall(pattern, section_text)\n",
    "    \n",
    "    data = []\n",
    "    for match in matches:\n",
    "        position, number, player, times = match\n",
    "        times_list = re.findall(r'(\\d+(?:\\+\\d+)?)\\'', times)\n",
    "        \n",
    "        player_data = {\n",
    "            'Position': position,\n",
    "            'Number': number,\n",
    "            'Player': player,\n",
    "            'In': times_list[0] + \"'\" if len(times_list) > 0 else None,\n",
    "            'Out': times_list[1] + \"'\" if len(times_list) > 1 else None,\n",
    "            'In2': times_list[2] + \"'\" if len(times_list) > 2 else None,\n",
    "            'Out2': times_list[3] + \"'\" if len(times_list) > 3 else None,\n",
    "            'In3': times_list[4] + \"'\" if len(times_list) > 4 else None,\n",
    "        }\n",
    "        data.append(player_data)\n",
    "    return data\n",
    "\n",
    "# Process all PDF files in the folder\n",
    "def process_all_pdfs(root_folder):\n",
    "    pdf_files = get_all_pdf_files(root_folder)\n",
    "    match_data = []\n",
    "    all_starting_lineups = []\n",
    "    all_substitutes = []\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        try:\n",
    "            # Extract match information\n",
    "            match_info = extract_match_data(pdf_file)\n",
    "            match_info[\"file\"] = pdf_file  # Add file path for reference\n",
    "            \n",
    "            # Extract lineup and substitutes\n",
    "            starting_lineup_df, substitutes_df = parse_lineup_and_substitutes(pdf_file)\n",
    "            starting_lineup_df['file'] = pdf_file\n",
    "            substitutes_df['file'] = pdf_file\n",
    "            \n",
    "            # Add match information to each player row\n",
    "            for key, value in match_info.items():\n",
    "                starting_lineup_df[key] = value\n",
    "                substitutes_df[key] = value\n",
    "            \n",
    "            # Append to results\n",
    "            match_data.append(match_info)\n",
    "            all_starting_lineups.append(starting_lineup_df)\n",
    "            all_substitutes.append(substitutes_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pdf_file}: {e}\")\n",
    "\n",
    "    # Combine data into DataFrames\n",
    "    match_df = pd.DataFrame(match_data)\n",
    "    starting_lineups_df = pd.concat(all_starting_lineups, ignore_index=True)\n",
    "    substitutes_df = pd.concat(all_substitutes, ignore_index=True)\n",
    "    \n",
    "    return match_df, starting_lineups_df, substitutes_df\n",
    "\n",
    "# Example usage\n",
    "root_folder = \"/Users/da-eunji/Downloads/Hackathon Data/match-reports\"\n",
    "match_df, starting_lineups_df, substitutes_df = process_all_pdfs(root_folder)\n",
    "\n",
    "# Save to CSV\n",
    "match_df.to_csv(\"match_data.csv\", index=False, encoding='utf-8-sig')\n",
    "starting_lineups_df.to_csv(\"starting_lineups.csv\", index=False, encoding='utf-8-sig')\n",
    "substitutes_df.to_csv(\"substitutes.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"CSV files created: match_data.csv, starting_lineups.csv, substitutes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee157cf1-bb52-4a54-afe3-c8f146f5478f",
   "metadata": {},
   "source": [
    "# Formation and Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ab70d6-6474-4c49-8326-be3fe3a532f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Formation Changes:\n",
      "                                                 Match  \\\n",
      "0     Rutgers Scarlet Knights - Seton Hall Pirates 1-3   \n",
      "1     Rutgers Scarlet Knights - Seton Hall Pirates 1-3   \n",
      "2     Rutgers Scarlet Knights - Seton Hall Pirates 1-3   \n",
      "3     Rutgers Scarlet Knights - Seton Hall Pirates 1-3   \n",
      "4     Rutgers Scarlet Knights - Seton Hall Pirates 1-3   \n",
      "...                                                ...   \n",
      "1462        San Diego Toreros - Washington Huskies 1-1   \n",
      "1463        San Diego Toreros - Washington Huskies 1-1   \n",
      "1464        San Diego Toreros - Washington Huskies 1-1   \n",
      "1465        San Diego Toreros - Washington Huskies 1-1   \n",
      "1466        San Diego Toreros - Washington Huskies 1-1   \n",
      "\n",
      "                         Team Formation Start_Time End_Time  \n",
      "0     Rutgers Scarlet Knights     4-1-2         1'      30'  \n",
      "1          Seton Hall Pirates     3-4-2        46'      59'  \n",
      "2     Rutgers Scarlet Knights     4-4-2         1'      34'  \n",
      "3          Seton Hall Pirates     4-4-2        34'      65'  \n",
      "4     Rutgers Scarlet Knights     3-4-2        59'      73'  \n",
      "...                       ...       ...        ...      ...  \n",
      "1462       Washington Huskies     2-3-1        26'      40'  \n",
      "1463        San Diego Toreros     2-3-1        74'      89'  \n",
      "1464       Washington Huskies     2-3-1        89'     101'  \n",
      "1465        San Diego Toreros     2-3-1        46'      68'  \n",
      "1466       Washington Huskies     2-3-1        95'     101'  \n",
      "\n",
      "[1467 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def extract_formation_changes(pdf_path):\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            page = pdf.pages[2]  # Extract from page 3 \n",
    "            text = page.extract_text()\n",
    "            \n",
    "            # Pattern for formations and times\n",
    "            pattern = r\"(\\d-\\d-\\d)\\s+(\\d+'\\s*[–—-]\\s*\\d+(?:\\+\\d+)?')\"\n",
    "            formation_data = []\n",
    "            \n",
    "            # Extract team names from filename\n",
    "            filename = os.path.basename(pdf_path)\n",
    "            teams = re.findall(r\"(.+?)\\s*-\\s*(.+?)\\s*\\d+-\\d+\\.pdf\", filename)\n",
    "            \n",
    "            if teams:\n",
    "                team1, team2 = teams[0]\n",
    "            else:\n",
    "                # Try to extract team names from page content\n",
    "                team_pattern = r\"([A-Za-z\\s]+)\\s+\\d+\\s*[–—-]\\s*\\d+\"\n",
    "                teams = re.findall(team_pattern, text)\n",
    "                if len(teams) >= 2:\n",
    "                    team1, team2 = teams[:2]\n",
    "                else:\n",
    "                    return pd.DataFrame()  # Return empty DataFrame if no teams found\n",
    "            \n",
    "            # Extract formations and time ranges\n",
    "            matches = re.findall(pattern, text)\n",
    "            \n",
    "            for idx, match in enumerate(matches):\n",
    "                formation, time_range = match\n",
    "                start_time, end_time = re.split(r'\\s*[–—-]\\s*', time_range)\n",
    "                \n",
    "                team = team1 if idx % 2 == 0 else team2\n",
    "                \n",
    "                formation_data.append({\n",
    "                    \"Match\": filename.replace(\".pdf\", \"\"),\n",
    "                    \"Team\": team.strip(),\n",
    "                    \"Formation\": formation,\n",
    "                    \"Start_Time\": start_time.strip(),\n",
    "                    \"End_Time\": end_time.strip()\n",
    "                })\n",
    "            \n",
    "            return pd.DataFrame(formation_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path}: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def process_all_pdfs(root_folder):\n",
    "    all_formations = []\n",
    "    \n",
    "    # Traverse all subdirectories\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.pdf'):\n",
    "                pdf_path = os.path.join(root, file)\n",
    "                formations_df = extract_formation_changes(pdf_path)\n",
    "                if not formations_df.empty:\n",
    "                    all_formations.append(formations_df)\n",
    "    \n",
    "    # Combine all results\n",
    "    if all_formations:\n",
    "        return pd.concat(all_formations, ignore_index=True)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# Example usage\n",
    "root_folder = \"/Users/da-eunji/Downloads/Hackathon Data/match-reports\"\n",
    "all_formations_df = process_all_pdfs(root_folder)\n",
    "\n",
    "# Display results\n",
    "print(\"All Formation Changes:\")\n",
    "print(all_formations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f283fdbc-e58f-41c7-95ac-29b5074d365d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon2024env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
